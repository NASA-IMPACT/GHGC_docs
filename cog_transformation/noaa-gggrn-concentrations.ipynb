{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Atmospheric Carbon Dioxide and Methane Concentrations from NOAA Global Monitoring Laboratory\n",
    "description: Documentation of data transformation\n",
    "author: Sanjog Thapa\n",
    "date: April 24, 2024\n",
    "execute:\n",
    "  freeze: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script was used to transform the CO₂ and CH₄ datasets in txt format with hourly granularity to JSON in daily and monthly granularity for visualization in the Greenhouse Gas (GHG) Center.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_aggregate(filepath):\n",
    "    \"\"\"\n",
    "    Reads hourly data from a .txt file, aggregates it to daily, and returns a list of JSON objects that can be readily visualized in chart.\n",
    "\n",
    "    Parameters:\n",
    "        filepath (str): The path to the file containing the data to be aggregated.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries representing aggregated data, with each dictionary containing\n",
    "              'date' and 'value' keys.\n",
    "\n",
    "    Description:\n",
    "        This function reads data from the specified file, aggregates it, and returns a list of JSON objects.\n",
    "        The function performs the following steps:\n",
    "        - Reads the content of the file.\n",
    "        - Extracts the header lines from the file to determine the structure of the data.\n",
    "        - Processes the data into a DataFrame.\n",
    "        - Filters and aggregates the data.\n",
    "        - Converts the aggregated data into a list of JSON objects, where each object contains 'date' and 'value' keys.\n",
    "\n",
    "    Exceptions:\n",
    "        - FileNotFoundError: If the specified file is not found.\n",
    "        - Exception: If any other exception occurs during the processing, the exception message is returned.\n",
    "\n",
    "    Note:\n",
    "        - The input file is expected to have a .txt format with header lines indicating the structure of the data.\n",
    "        - The function aggregates data from hourly to daily intervals.\n",
    "        - The returned JSON list is suitable for use in frontend applications to visualize the aggregated data.\n",
    "\n",
    "    Example:\n",
    "        aggregated_data = daily_aggregate(\"/path/to/data_file.txt\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "            file_content_str = file.read()\n",
    "            # split the string text based on new line\n",
    "            file_content_list = file_content_str.split(\"\\n\")\n",
    "            # get the header lines. its mentioned in the file's first line.\n",
    "            header_lines = file_content_list[0].split(\":\")[-1]\n",
    "            header_lines = int(header_lines)\n",
    "            # Slice the non header part of the data. and the last empty element\n",
    "            str_datas = file_content_list[header_lines - 1: -1]\n",
    "            data = [data.replace(\"\\n\", \"\").split(\" \") for data in str_datas]\n",
    "            # seperate table body and head to form dataframe\n",
    "            table_head = data[0]\n",
    "            table_body = data[1:]\n",
    "            dataframe = pd.DataFrame(table_body, columns=table_head)\n",
    "            dataframe['value'] = dataframe['value'].astype(float)\n",
    "            # Filter data\n",
    "            mask = (dataframe[\"qcflag\"] == \"...\") & (dataframe[\"value\"] != 0) & (dataframe[\"value\"] != -999)\n",
    "            filtered_df = dataframe[mask].reset_index(drop=True)\n",
    "            # Aggregate data (hourly into daily)\n",
    "            aggregated_df = filtered_df.groupby(['year', 'month', 'day'])['value'].mean().reset_index()\n",
    "            aggregated_df['value'] = aggregated_df['value'].round(2)\n",
    "            # necessary columns, processed df\n",
    "            aggregated_df['datetime'] = pd.to_datetime(aggregated_df[['year', 'month', 'day']])\n",
    "            aggregated_df['datetime'] = aggregated_df['datetime'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "            processed_df = aggregated_df[['datetime', 'value']]\n",
    "            processed_df = processed_df.sort_values(by='datetime')\n",
    "            # dict formation, needed for frontend [{date: , value: }]\n",
    "            json_list = []\n",
    "            for _, row in processed_df.iterrows():\n",
    "                json_obj = {'date': row['datetime'], 'value': row['value']}\n",
    "                json_list.append(json_obj)\n",
    "            return json_list\n",
    "    except FileNotFoundError:\n",
    "        return \"File not found\"\n",
    "    except Exception as e:\n",
    "        return f\"Exception occured {e}\"\n",
    "\n",
    "\n",
    "def monthly_aggregate(filepath):\n",
    "    \"\"\"\n",
    "    Reads hourly data from a .txt file, aggregates it to monthly, and returns a list of JSON objects that can be readily visualized in chart.\n",
    "\n",
    "    Parameters:\n",
    "        filepath (str): The path to the file containing the data to be aggregated.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries representing aggregated data, with each dictionary containing\n",
    "              'date' and 'value' keys.\n",
    "\n",
    "    Description:\n",
    "        This function reads data from the specified file, aggregates it, and returns a list of JSON objects.\n",
    "        The function performs the following steps:\n",
    "        - Reads the content of the file.\n",
    "        - Extracts the header lines from the file to determine the structure of the data.\n",
    "        - Processes the data into a DataFrame.\n",
    "        - Filters and aggregates the data.\n",
    "        - Converts the aggregated data into a list of JSON objects, where each object contains 'date' and 'value' keys.\n",
    "\n",
    "    Exceptions:\n",
    "        - FileNotFoundError: If the specified file is not found.\n",
    "        - Exception: If any other exception occurs during the processing, the exception message is returned.\n",
    "\n",
    "    Note:\n",
    "        - The input file is expected to have a .txt format with header lines indicating the structure of the data.\n",
    "        - The function aggregates data from hourly to daily intervals.\n",
    "        - The returned JSON list is suitable for use in frontend applications to visualize the aggregated data.\n",
    "\n",
    "    Example:\n",
    "        aggregated_data = monthly_aggregate(\"/path/to/data_file.txt\")\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "            file_content_str = file.read()\n",
    "            # split the string text based on new line\n",
    "            file_content_list = file_content_str.split(\"\\n\")\n",
    "            # get the header lines. its mentioned in the file's first line.\n",
    "            header_lines = file_content_list[0].split(\":\")[-1]\n",
    "            header_lines = int(header_lines)\n",
    "            # Slice the non header part of the data. and the last empty element\n",
    "            str_datas = file_content_list[header_lines - 1: -1]\n",
    "            data = [data.replace(\"\\n\", \"\").split(\" \") for data in str_datas]\n",
    "            # seperate table body and head to form dataframe\n",
    "            table_head = data[0]\n",
    "            table_body = data[1:]\n",
    "            dataframe = pd.DataFrame(table_body, columns=table_head)\n",
    "            dataframe['value'] = dataframe['value'].astype(float)\n",
    "            # Filter data\n",
    "            mask = (dataframe[\"qcflag\"] == \"...\") & (dataframe[\"value\"] != 0) & (dataframe[\"value\"] != -999)\n",
    "            filtered_df = dataframe[mask].reset_index(drop=True)\n",
    "            # Aggregate data (hourly into monthly)\n",
    "            aggregated_df = filtered_df.groupby(['year', 'month'])['value'].mean().reset_index()\n",
    "            aggregated_df['value'] = aggregated_df['value'].round(2)\n",
    "            # necessary columns, processed df\n",
    "            aggregated_df['datetime'] = pd.to_datetime(aggregated_df[['year', 'month']].assign(day=1))\n",
    "            aggregated_df['datetime'] = aggregated_df['datetime'].dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "            processed_df = aggregated_df[['datetime', 'value']]\n",
    "            processed_df = processed_df.sort_values(by='datetime')\n",
    "            # dict formation, needed for frontend [{date: , value: }]\n",
    "            json_list = []\n",
    "            for _, row in processed_df.iterrows():\n",
    "                json_obj = {'date': row['datetime'], 'value': row['value']}\n",
    "                json_list.append(json_obj)\n",
    "            return json_list\n",
    "    except FileNotFoundError:\n",
    "        return \"File not found\"\n",
    "    except Exception as e:\n",
    "        return f\"Exception occured {e}\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if filepath argument is provided\n",
    "    if len(sys.argv) != 2:\n",
    "        print(\"Usage: python aggregrate.py <daily|monthly> <filepath>\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Get the filepath from command line argument\n",
    "    frequency = sys.argv[1]\n",
    "    hourly_data_filepath = sys.argv[2]\n",
    "\n",
    "    # Call the aggregate function with the provided filepath\n",
    "    if (frequency == \"daily\"):\n",
    "        result = daily_aggregate(hourly_data_filepath)\n",
    "    elif (frequency == \"monthly\"):\n",
    "        result = monthly_aggregate(hourly_data_filepath)\n",
    "    else:\n",
    "        print(\"Usage: python aggregrate.py <daily|monthly> <filepath>\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    if result is not None:\n",
    "        print(result)\n",
    "        # save the json file for reference\n",
    "        out_path = f\"{hourly_data_filepath.split(\"/\")[-1]}.json\"\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            json.dump(result, file)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
