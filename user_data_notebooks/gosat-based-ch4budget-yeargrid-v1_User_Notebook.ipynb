{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: GOSAT-based Top-down Total and Natural Methane Emissions\n",
    "description: Total and natural methane emissions for 2019 summed to a 1° resolution grid. Methane values for both prior to and after inclusion of GOSAT data to the GEOS-Chem global chemistry transport model, version 1.0\n",
    "author: Siddharth Chaudhary, Vishal Gaur\n",
    "date: 21 September 2023\n",
    "execute:\n",
    "   freeze: true\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "1. Identify available dates and temporal frequency of observations for the given collection using the GHGC API `/stac` endpoint. The collection processed in this notebook is the gridded methane emissions data product.\n",
    "2. Pass the STAC item into the raster API `/stac/tilejson.json `endpoint.\n",
    "3. Using `folium.plugins.DualMap`, we will visualize two tiles (side-by-side), allowing us to compare time points. \n",
    "4. After the visualization, we will perform zonal statistics for a given polygon.\n",
    "\n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data\n",
    "\n",
    "The NASA Carbon Monitoring System Flux (CMS-Flux) team analyzed remote sensing observations from Japan’s Greenhouse gases Observing SATellite (GOSAT) to produce the global Committee on Earth Observation Satellites (CEOS) CH₄ Emissions data product. They used an analytic Bayesian inversion approach and the GEOS-Chem global chemistry transport model to quantify annual methane (CH₄) emissions and their uncertainties at a spatial resolution of 1° by 1° and then projected these to each country for 2019.\n",
    "\n",
    "For more information regarding this dataset, please visit the [GOSAT-based Top-down Total and Natural Methane Emissions](https://earth.gov/ghgcenter/data-catalog/gosat-based-ch4budget-yeargrid-v1) data overview page."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install the Required Libraries\n",
    "Required libraries are pre-installed on the GHG Center Hub. If you need to run this notebook elsewhere, please install them with this line in a code cell:\n",
    "\n",
    "%pip install requests folium rasterstats pystac_client pandas matplotlib --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the STAC API\n",
    "First, we are going to import the required libraries. Once imported, they allow better executing a query in the GHG Center Spatio Temporal Asset Catalog (STAC) Application Programming Interface (API) where the granules for this collection are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the following libraries\n",
    "import requests\n",
    "import folium\n",
    "import folium.plugins\n",
    "from folium import Map, TileLayer\n",
    "from pystac_client import Client\n",
    "import branca\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide STAC and RASTER API endpoints\n",
    "STAC_API_URL = \"https://earth.gov/ghgcenter/api/stac\"\n",
    "RASTER_API_URL = \"https://earth.gov/ghgcenter/api/raster\"\n",
    "\n",
    "# Please use the collection name similar to the one used in STAC collection.\n",
    "\n",
    "# Name of the collection for gosat budget methane. \n",
    "collection_name = \"gosat-based-ch4budget-yeargrid-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the collection from STAC collections using appropriate endpoint.\n",
    "collection = requests.get(f\"{STAC_API_URL}/collections/{collection_name}\").json()\n",
    "collection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the contents of our `collection` under the `temporal` variable, we see that the data is available from January 2012 to December 2018. By looking at the `dashboard:time density`, we observe that the data is available for only one year, i.e. 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the required temporal information\n",
    "temporal_extent = collection['extent']['temporal']['interval'][0]\n",
    "start_date = temporal_extent[0].split('T')[0]\n",
    "end_date = temporal_extent[1].split('T')[0]\n",
    "temporal_resolution = collection['dashboard:time_density']\n",
    "\n",
    "# Final print statement\n",
    "print(f\"Start Date = {start_date}\")\n",
    "print(f\"End Date = {end_date}\")\n",
    "print(f\"Temporal Resolution = {temporal_resolution}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_count(collection_id):\n",
    "    count = 0\n",
    "    items_url = f\"{STAC_API_URL}/collections/{collection_id}/items\"\n",
    "\n",
    "    while True:\n",
    "        response = requests.get(items_url)\n",
    "\n",
    "        if not response.ok:\n",
    "            print(\"error getting items\")\n",
    "            exit()\n",
    "\n",
    "        stac = response.json()\n",
    "        count += int(stac[\"context\"].get(\"returned\", 0))\n",
    "        next = [link for link in stac[\"links\"] if link[\"rel\"] == \"next\"]\n",
    "\n",
    "        if not next:\n",
    "            break\n",
    "        items_url = next[0][\"href\"]\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total number of items available\n",
    "number_of_items = get_item_count(collection_name)\n",
    "items = requests.get(f\"{STAC_API_URL}/collections/{collection_name}/items?limit={number_of_items}\").json()[\"features\"]\n",
    "print(f\"Found {len(items)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining the first item in the collection\n",
    "items[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we enter minimum and maximum values to provide our upper and lower bounds in `rescale_values.`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Changes in GOSAT Methane budgets (CH4) Levels Using the Raster API\n",
    "\n",
    "In this notebook, we will explore the impacts of methane emissions and by examining changes over time in urban regions. We will visualize the outputs on a map using `folium.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To access the year value from each item more easily, this will let us query more explicity by year and month (e.g., 2020-02)\n",
    "items = {item[\"properties\"][\"start_datetime\"][:10]: item for item in items} \n",
    "asset_name = \"prior-total\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the min and max values for a specific item\n",
    "rescale_values = {\"max\":items[list(items.keys())[0]][\"assets\"][asset_name][\"raster:bands\"][0][\"histogram\"][\"max\"], \"min\":items[list(items.keys())[0]][\"assets\"][asset_name][\"raster:bands\"][0][\"histogram\"][\"min\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will pass the item id, collection name, and `rescaling_factor` to the `Raster API` endpoint. We will do this for first January 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = \"rainbow\" # please select the color ramp from matplotlib library.\n",
    "january_2019_tile = requests.get(\n",
    "    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items['2019-01-01']['collection']}&item={items['2019-01-01']['id']}\"\n",
    "    f\"&assets={asset_name}\"\n",
    "    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n",
    "    f\"&rescale={rescale_values['min']},{rescale_values['max']}\", \n",
    ").json()\n",
    "january_2019_tile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing CH₄ Emissions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial zoom and center of map for CH₄ Layer\n",
    "# Centre of map [latitude,longitude]\n",
    "map_ = folium.Map(location=(34, -118), zoom_start=6)\n",
    "\n",
    "# January 2019\n",
    "map_layer_2019 = TileLayer(\n",
    "    tiles=january_2019_tile[\"tiles\"][0],\n",
    "    attr=\"GHG\",\n",
    "    opacity=0.7,\n",
    ")\n",
    "map_layer_2019.add_to(map_)\n",
    "\n",
    "# # January 2012\n",
    "# map_layer_2012 = TileLayer(\n",
    "#     tiles=january_2012_tile[\"tiles\"][0],\n",
    "#     attr=\"GHG\",\n",
    "#     opacity=0.7,\n",
    "# )\n",
    "# map_layer_2012.add_to(map_.m2)\n",
    "\n",
    "# visualising the map\n",
    "map_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Zonal Statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform zonal statistics, first we need to create a polygon. In this use case we are creating a polygon in Texas (USA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texas, USA\n",
    "texas_aoi = {\n",
    "    \"type\": \"Feature\",\n",
    "    \"properties\": {},\n",
    "    \"geometry\": {\n",
    "        \"coordinates\": [\n",
    "            [\n",
    "                # [13.686159004559698, -21.700046934333145],\n",
    "                # [13.686159004559698, -23.241974326585833],\n",
    "                # [14.753560168039911, -23.241974326585833],\n",
    "                # [14.753560168039911, -21.700046934333145],\n",
    "                # [13.686159004559698, -21.700046934333145],\n",
    "                [-95, 29],\n",
    "                [-95, 33],\n",
    "                [-104, 33],\n",
    "                [-104,29],\n",
    "                [-95, 29]\n",
    "            ]\n",
    "        ],\n",
    "        \"type\": \"Polygon\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will plug in the coordinates for a location inside the the polygon and a zoom level\n",
    "\n",
    "aoi_map = Map(\n",
    "    tiles=\"OpenStreetMap\",\n",
    "    location=[\n",
    "        30,-100\n",
    "    ],\n",
    "    zoom_start=6,\n",
    ")\n",
    "\n",
    "folium.GeoJson(texas_aoi, name=\"Texas, USA\").add_to(aoi_map)\n",
    "aoi_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total number of items available\n",
    "items = requests.get(\n",
    "    f\"{STAC_API_URL}/collections/{collection_name}/items?limit=300\"\n",
    ").json()[\"features\"]\n",
    "print(f\"Found {len(items)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the first item\n",
    "items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bounding box should be passed to the geojson param as a geojson Feature or FeatureCollection\n",
    "def generate_stats(item, geojson):\n",
    "    result = requests.post(\n",
    "        f\"{RASTER_API_URL}/cog/statistics\",\n",
    "        params={\"url\": item[\"assets\"][asset_name][\"href\"]},\n",
    "        json=geojson,\n",
    "    ).json()\n",
    "    return {\n",
    "        **result[\"properties\"],\n",
    "        \"datetime\": item[\"properties\"][\"start_datetime\"][:10],\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the function above we can generate the statistics for the AOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "stats = [generate_stats(item, texas_aoi) for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stats(stats_json) -> pd.DataFrame:\n",
    "    df = pd.json_normalize(stats_json)\n",
    "    df.columns = [col.replace(\"statistics.b1.\", \"\") for col in df.columns]\n",
    "    df[\"date\"] = pd.to_datetime(df[\"datetime\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "df = clean_stats(stats)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(items[0][\"properties\"][\"start_datetime\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_2016 = requests.get(\n",
    "    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items[0]['collection']}&item={items[0]['id']}\"\n",
    "    f\"&assets={asset_name}\"\n",
    "    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n",
    "    f\"&rescale={rescale_values['min']},{rescale_values['max']}\",\n",
    ").json()\n",
    "tile_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use bbox initial zoom and map\n",
    "# Set up a map located w/in event bounds\n",
    "\n",
    "aoi_map_bbox = Map(\n",
    "    tiles=\"OpenStreetMap\",\n",
    "    location=[\n",
    "        30,-100\n",
    "    ],\n",
    "    zoom_start=8,\n",
    ")\n",
    "\n",
    "map_layer = TileLayer(\n",
    "    tiles=tile_2016[\"tiles\"][0],\n",
    "    attr=\"GHG\", opacity = 0.5\n",
    ")\n",
    "\n",
    "map_layer.add_to(aoi_map_bbox)\n",
    "\n",
    "aoi_map_bbox"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we have successfully completed the following steps for the STAC collection for the GOSAT-based Top-down Total and Natural Methane Emissions dataset.\n",
    "\n",
    "1.  Install and import the necessary libraries\n",
    "2.  Fetch the collection from STAC collections using the appropriate endpoints\n",
    "3.  Count the number of existing granules within the collection\n",
    "4.  Map the methane emission levels\n",
    "5.  Generate zonal statistics for the area of interest (AOI)\n",
    "\n",
    "If you have any questions regarding this user notebook, please contact us using the [feedback form](https://docs.google.com/forms/d/e/1FAIpQLSeVWCrnca08Gt_qoWYjTo6gnj1BEGL4NCUC9VEiQnXA02gzVQ/viewform)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
