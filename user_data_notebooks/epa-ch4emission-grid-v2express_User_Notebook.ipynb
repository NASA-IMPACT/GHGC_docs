{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: U.S. Gridded Anthropogenic Methane Emissions Inventory\n",
    "description: Spatially disaggregated 0.1°x 0.1° annual maps of U.S. anthropogenic methane emissions, consistent with the U.S. Inventory of Greenhouse Gas Emissions and Sinks\n",
    "authors: Siddharth Chaudhary, Vishal Gaur\n",
    "published: 29 June 2023\n",
    "execute:\n",
    "   freeze: true\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this notebook\n",
    "\n",
    "You can launch this notebook in the US GHG Center JupyterHub by clicking the link below.\n",
    "\n",
    "[Launch in the US GHG Center JupyterHub (requires access)](https://hub.ghg.center/hub/user-redirect/lab/tree/ghgc-docs/user_data_notebooks/epa-ch4emission-grid-v2express_User_Notebook.ipynb)",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "1. Identify available dates and temporal frequency of observations for the given collection using the GHGC API `/stac` endpoint. The collection processed in this notebook is the gridded methane emissions data product.\n",
    "2. Pass the STAC item into the raster API `/stac/tilejson.json `endpoint.\n",
    "3. Using `folium.plugins.DualMap`, we will visualize two tiles (side-by-side), allowing us to compare time points. \n",
    "4. After the visualization, we will perform zonal statistics for a given polygon.\n",
    "\n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data\n",
    "\n",
    "The gridded EPA U.S. anthropogenic methane greenhouse gas inventory (gridded GHGI) includes spatially disaggregated (0.1 deg x 0.1 deg or approximately 10 x 10 km resolution) maps of annual anthropogenic methane emissions (for the contiguous United States (CONUS), consistent with national annual U.S. anthropogenic methane emissions reported in the U.S. EPA [Inventory of U.S. Greenhouse Gas Emissions and Sinks](https://www.epa.gov/ghgemissions/inventory-us-greenhouse-gas-emissions-and-sinks) (U.S. GHGI). This V2 Express Extension dataset contains methane emissions provided as fluxes, in units of molecules of methane per square cm per second, for over 25 individual emission source categories, including those from agriculture, petroleum and natural gas systems, coal mining, and waste. The data have been converted from their original NetCDF format to Cloud-Optimized GeoTIFF (COG) for use in the US GHG Center, thereby enabling user exploration of spatial anthropogenic methane emissions and their trends.\n",
    "\n",
    "For more information regarding this dataset, please visit the [U.S. Gridded Anthropogenic Methane Emissions Inventory](https://earth.gov/ghgcenter/data-catalog/epa-ch4emission-yeargrid-v2express) data overview page."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install the Required Libraries\n",
    "Required libraries are pre-installed on the GHG Center Hub. If you need to run this notebook elsewhere, please install them with this line in a code cell:\n",
    "\n",
    "%pip install requests folium rasterstats pystac_client pandas matplotlib --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the STAC API\n",
    "First, we are going to import the required libraries. Once imported, they allow better executing a query in the GHG Center Spatio Temporal Asset Catalog (STAC) Application Programming Interface (API) where the granules for this collection are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the following libraries\n",
    "import requests\n",
    "import folium\n",
    "import folium.plugins\n",
    "from folium import Map, TileLayer\n",
    "from pystac_client import Client\n",
    "import branca\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the STAC and RASTER API endpoints\n",
    "# The endpoint is referring to a location within the API that executes a request on a data collection nesting on the server.\n",
    "\n",
    "# The STAC API is a catalog of all the existing data collections that are stored in the GHG Center.\n",
    "STAC_API_URL = \"https://earth.gov/ghgcenter/api/stac\"\n",
    "\n",
    "# The RASTER API is used to fetch collections for visualization\n",
    "RASTER_API_URL = \"https://earth.gov/ghgcenter/api/raster\"\n",
    "\n",
    "# The collection name is used to fetch the dataset from the STAC API. First, we define the collection name as a variable\n",
    "# Name of the collection for gridded methane dataset \n",
    "collection_name = \"epa-ch4emission-yeargrid-v2express\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the collection from the STAC API using the appropriate endpoint\n",
    "# The 'requests' library allows a HTTP request possible\n",
    "collection = requests.get(f\"{STAC_API_URL}/collections/{collection_name}\").json()\n",
    "\n",
    "# Print the properties of the collection to the console\n",
    "collection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the contents of our `collection` under the `temporal` variable, we see that the data is available from January 2012 to December 2020. By looking at the `dashboard:time density`, we observe that the periodic frequency of these observations is yearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that would search for a data collection in the US GHG Center STAC API\n",
    "\n",
    "# First, we need to define the function\n",
    "# The name of the function = \"get_item_count\"\n",
    "# The argument that will be passed through the defined function = \"collection_id\"\n",
    "def get_item_count(collection_id):\n",
    "\n",
    "    # Set a counter for the number of items existing in the collection\n",
    "    count = 0\n",
    "\n",
    "    # Define the path to retrieve the granules (items) of the collection of interest in the STAC API\n",
    "    items_url = f\"{STAC_API_URL}/collections/{collection_id}/items\"\n",
    "\n",
    "    # Run a while loop to make HTTP requests until there are no more URLs associated with the collection in the STAC API\n",
    "    while True:\n",
    "\n",
    "        # Retrieve information about the granules by sending a \"get\" request to the STAC API using the defined collection path\n",
    "        response = requests.get(items_url)\n",
    "\n",
    "        # If the items do not exist, print an error message and quit the loop\n",
    "        if not response.ok:\n",
    "            print(\"error getting items\")\n",
    "            exit()\n",
    "\n",
    "        # Return the results of the HTTP response as JSON\n",
    "        stac = response.json()\n",
    "\n",
    "        # Increase the \"count\" by the number of items (granules) returned in the response\n",
    "        count += int(stac[\"context\"].get(\"returned\", 0))\n",
    "\n",
    "        # Retrieve information about the next URL associated with the collection in the STAC API (if applicable)\n",
    "        next = [link for link in stac[\"links\"] if link[\"rel\"] == \"next\"]\n",
    "\n",
    "        # Exit the loop if there are no other URLs\n",
    "        if not next:\n",
    "            break\n",
    "        \n",
    "        # Ensure the information gathered by other STAC API links associated with the collection are added to the original path\n",
    "        # \"href\" is the identifier for each of the tiles stored in the STAC API\n",
    "        items_url = next[0][\"href\"]\n",
    "\n",
    "    # Return the information about the total number of granules found associated with the collection\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function created above \"get_item_count\" to the data collection\n",
    "number_of_items = get_item_count(collection_name)\n",
    "\n",
    "# Get the information about the number of granules found in the collection\n",
    "items = requests.get(f\"{STAC_API_URL}/collections/{collection_name}/items?limit={number_of_items}\").json()[\"features\"]\n",
    "\n",
    "# Print the total number of items (granules) found\n",
    "print(f\"Found {len(items)} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes sense as there are 9 years between 2012 - 2020, meaning 9 records in total.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the first item in the collection\n",
    "# Keep in mind that a list starts from 0, 1, 2... therefore items[0] is referring to the first item in the list/collection\n",
    "items[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Changes in Methane (CH4) Levels Using the Raster API\n",
    "\n",
    "In this notebook, we will explore the impacts of methane emissions and by examining changes over time in urban regions. We will visualize the outputs on a map using `folium`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create a dictionary where the start datetime values for each granule is queried more explicitly by year and month (e.g., 2020-02)\n",
    "items = {item[\"properties\"][\"datetime\"][:7]: item for item in items} \n",
    "\n",
    "# Next, we need to specify the asset name for this collection\n",
    "# The asset name is referring to the raster band containing the pixel values for the parameter of interest\n",
    "# For the case of the U.S. Gridded Anthropogenic Methane Emissions Inventory collection, the parameter of interest is “surface-coal”\n",
    "asset_name = \"surface-coal\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we enter minimum and maximum values to provide our upper and lower bounds in `rescale_values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the min and max values for a specific item\n",
    "rescale_values = {\"max\":items[list(items.keys())[0]][\"assets\"][asset_name][\"raster:bands\"][0][\"histogram\"][\"max\"], \"min\":items[list(items.keys())[0]][\"assets\"][asset_name][\"raster:bands\"][0][\"histogram\"][\"min\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will pass the item id, collection name, asset name, and the `rescaling factor` to the `Raster API` endpoint. We will do this twice, once for January 2018 and again for January 2012, so that we can visualize each event independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a color map for displaying the first observation (event)\n",
    "# Please refer to matplotlib library if you'd prefer choosing a different color ramp.\n",
    "# For more information on Colormaps in Matplotlib, please visit https://matplotlib.org/stable/users/explain/colors/colormaps.html\n",
    "color_map = \"rainbow\" \n",
    "\n",
    "# Make a GET request to retrieve information for the 2018 tile \n",
    "january_2018_tile = requests.get(\n",
    "\n",
    "    # Pass the collection name, the item number in the list, and its ID\n",
    "    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items['2018-01']['collection']}&item={items['2018-01']['id']}\"\n",
    "\n",
    "    # Pass the asset name\n",
    "    f\"&assets={asset_name}\"\n",
    "\n",
    "    # Pass the color formula and colormap for custom visualization\n",
    "    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n",
    "\n",
    "    # Pass the minimum and maximum values for rescaling\n",
    "    f\"&rescale={rescale_values['min']},{rescale_values['max']}\", \n",
    "\n",
    "# Return the response in JSON format\n",
    ").json()\n",
    "\n",
    "# Print the properties of the retrieved granule to the console\n",
    "january_2018_tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a GET request to retrieve information for the 2012 tile \n",
    "january_2012_tile = requests.get(\n",
    "\n",
    "    # Pass the collection name, the item number in the list, and its ID\n",
    "    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items['2012-01']['collection']}&item={items['2012-01']['id']}\"\n",
    "\n",
    "    # Pass the asset name\n",
    "    f\"&assets={asset_name}\"\n",
    "\n",
    "    # Pass the color formula and colormap for custom visualization\n",
    "    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n",
    "\n",
    "    # Pass the minimum and maximum values for rescaling\n",
    "    f\"&rescale={rescale_values['min']},{rescale_values['max']}\", \n",
    "\n",
    "# Return the response in JSON format\n",
    ").json()\n",
    "\n",
    "# Print the properties of the retrieved granule to the console\n",
    "january_2012_tile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing CH₄ emissions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial zoom and center of map for CH₄ Layer\n",
    "# Centre of map [latitude,longitude]\n",
    "# 'folium.plugins' allows mapping side-by-side\n",
    "map_ = folium.plugins.DualMap(location=(34, -118), zoom_start=6)\n",
    "\n",
    "# Define the first map layer (January 2018)\n",
    "map_layer_2018 = TileLayer(\n",
    "    tiles=january_2018_tile[\"tiles\"][0], # Path to retrieve the tile\n",
    "    attr=\"GHG\", # Set the attribution\n",
    "    opacity=0.7, # Adjust the transparency of the layer\n",
    ")\n",
    "\n",
    "# Add the first layer to the Dual Map\n",
    "map_layer_2018.add_to(map_.m1)\n",
    "\n",
    "# Define the second map layer (January 2012)\n",
    "map_layer_2012 = TileLayer(\n",
    "    tiles=january_2012_tile[\"tiles\"][0], # Path to retrieve the tile\n",
    "    attr=\"GHG\", # Set the attribution\n",
    "    opacity=0.7, # Adjust the transparency of the layer\n",
    ")\n",
    "\n",
    "# Add the second layer to the Dual Map\n",
    "map_layer_2012.add_to(map_.m2)\n",
    "\n",
    "# Visualize the Dual Map\n",
    "map_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Zonal Statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform zonal statistics, first we need to create a polygon. In this use case we are creating a polygon in Texas (USA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texas, USA\n",
    "texas_aoi = {\n",
    "    \"type\": \"Feature\", # Create a feature object\n",
    "    \"properties\": {},\n",
    "    \"geometry\": { # Set the bounding coordinates for the polygon\n",
    "        \"coordinates\": [\n",
    "            [\n",
    "                # [13.686159004559698, -21.700046934333145],\n",
    "                # [13.686159004559698, -23.241974326585833],\n",
    "                # [14.753560168039911, -23.241974326585833],\n",
    "                # [14.753560168039911, -21.700046934333145],\n",
    "                # [13.686159004559698, -21.700046934333145],\n",
    "                [-95, 29], # South-east bounding coordinate\n",
    "                [-95, 33], # North-east bounding coordinate\n",
    "                [-104,33], # North-west bounding coordinate\n",
    "                [-104,29], # South-west bounding coordinate\n",
    "                [-95, 29]  # South-east bounding coordinate (closing the polygon)\n",
    "            ]\n",
    "        ],\n",
    "        \"type\": \"Polygon\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new map to display the generated polygon\n",
    "# We'll plug in the coordinates for a location\n",
    "# Central to the study area and a reasonable zoom level\n",
    "aoi_map = Map(\n",
    "\n",
    "    # Base map is set to OpenStreetMap\n",
    "    tiles=\"OpenStreetMap\",\n",
    "\n",
    "    # Define the spatial properties for the map\n",
    "    location=[\n",
    "        30,-100\n",
    "    ],\n",
    "\n",
    "    # Set the zoom value\n",
    "    zoom_start=6,\n",
    ")\n",
    "\n",
    "# Insert the polygon to the map\n",
    "folium.GeoJson(texas_aoi, name=\"Texas, USA\").add_to(aoi_map)\n",
    "\n",
    "# Visualize the map\n",
    "aoi_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total number of items available within the collection\n",
    "items = requests.get(\n",
    "    f\"{STAC_API_URL}/collections/{collection_name}/items?limit=300\"\n",
    ").json()[\"features\"]\n",
    "\n",
    "# Print the total number of items (granules) found\n",
    "print(f\"Found {len(items)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the first item in the collection\n",
    "items[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we created the polygon for the area of interest, we need to develop a function that runs through the data collection and generates the statistics for a specific item (granule) within the boundaries of the AOI polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bounding box should be passed to the geojson param as a geojson Feature or FeatureCollection\n",
    "# Create a function that retrieves information regarding a specific granule using its asset name and raster identifier and generates the statistics for it\n",
    "# The function takes an item (granule) and a JSON (polygon) as input parameters\n",
    "def generate_stats(item, geojson):\n",
    "\n",
    "    # A POST request is made to submit the data associated with the item of interest (specific observation) within the boundaries of the polygon to compute its statistics\n",
    "    result = requests.post(\n",
    "\n",
    "        # Raster API Endpoint for computing statistics\n",
    "        f\"{RASTER_API_URL}/cog/statistics\",\n",
    "\n",
    "        # Pass the URL to the item, asset name, and raster identifier as parameters\n",
    "        params={\"url\": item[\"assets\"][asset_name][\"href\"]},\n",
    "\n",
    "        # Send the GeoJSON object (polygon) along with the request\n",
    "        json=geojson,\n",
    "\n",
    "    # Return the response in JSON format\n",
    "    ).json()\n",
    "\n",
    "    # Return a dictionary containing the computed statistics along with the item's datetime information.\n",
    "    return {\n",
    "        **result[\"properties\"],\n",
    "        \"datetime\": item[\"properties\"][\"datetime\"],\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the function above we can generate the statistics for the AOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# %%time = Wall time (execution time) for running the code below\n",
    "\n",
    "# Generate statistics using the created function \"generate_stats\" within the bounding box defined by the polygon\n",
    "stats = [generate_stats(item, texas_aoi) for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the stats for the first item in the collection\n",
    "stats[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that goes through every single item in the collection and populates their properties - including the minimum, maximum, and sum of their values - in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that converts statistics in JSON format into a pandas DataFrame\n",
    "def clean_stats(stats_json) -> pd.DataFrame:\n",
    "\n",
    "    # Normalize the JSON data\n",
    "    df = pd.json_normalize(stats_json)\n",
    "\n",
    "    # Replace the naming \"statistics.b1\" in the columns\n",
    "    df.columns = [col.replace(\"statistics.b1.\", \"\") for col in df.columns]\n",
    "\n",
    "    # Set the datetime format\n",
    "    df[\"date\"] = pd.to_datetime(df[\"datetime\"])\n",
    "\n",
    "    # Return the cleaned format\n",
    "    return df\n",
    "\n",
    "# Apply the generated function on the stats data\n",
    "df = clean_stats(stats)\n",
    "\n",
    "# Display the stats for the first 5 granules in the collection in the table\n",
    "# Change the value in the parenthesis to show more or a smaller number of rows in the table\n",
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data as a Time Series\n",
    "We can now explore the gridded methane emission (Domestic Wastewater Treatment & Discharge (5D)) time series (January 2000 -December 2021) available for the Dallas, Texas area of the U.S. We can plot the data set using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure size: 20 representing the width, 10 representing the height\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "\n",
    "plt.plot(\n",
    "    df[\"date\"], # X-axis: sorted date\n",
    "    df[\"max\"],  # Y-axis: maximum CH4 emission\n",
    "    color=\"red\", # Line color\n",
    "    linestyle=\"-\", # Line style\n",
    "    linewidth=0.5, # Line width\n",
    "    label=\"Max CH4 emissions\", # Legend label\n",
    ")\n",
    "\n",
    "# Display legend\n",
    "plt.legend()\n",
    "\n",
    "# Insert label for the X-axis\n",
    "plt.xlabel(\"Years\")\n",
    "\n",
    "# Insert label for the Y-axis\n",
    "plt.ylabel(\"CH4 emissions Molecules CH₄/cm²/s\")\n",
    "\n",
    "# Insert title for the plot\n",
    "plt.title(\"CH4 gridded methane emission from Domestic Wastewater Treatment & Discharge (5D) for Texas, Dallas (2012-202)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the properties for the 3rd item in the collection\n",
    "print(items[2][\"properties\"][\"datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A GET request is made for the 2016 tile\n",
    "tile_2016 = requests.get(\n",
    "\n",
    "    # Pass the collection name, the item number in the list, and its ID\n",
    "    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items[2]['collection']}&item={items[2]['id']}\"\n",
    "\n",
    "    # Pass the asset name\n",
    "    f\"&assets={asset_name}\"\n",
    "\n",
    "    # Pass the color formula and colormap for custom visualization\n",
    "    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n",
    "\n",
    "    # Pass the minimum and maximum values for rescaling\n",
    "    f\"&rescale={rescale_values['min']},{rescale_values['max']}\",\n",
    "\n",
    "# Return the response in JSON format\n",
    ").json()\n",
    "\n",
    "# Print the properties of the retrieved granule to the console\n",
    "tile_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new map to display the 2016 tile\n",
    "aoi_map_bbox = Map(\n",
    "\n",
    "    # Base map is set to OpenStreetMap\n",
    "    tiles=\"OpenStreetMap\",\n",
    "\n",
    "    # Set the center of the map\n",
    "    location=[\n",
    "        30,-100\n",
    "    ],\n",
    "\n",
    "    # Set the zoom value\n",
    "    zoom_start=8,\n",
    ")\n",
    "\n",
    "# Define the map layer\n",
    "map_layer = TileLayer(\n",
    "\n",
    "    # Path to retrieve the tile\n",
    "    tiles=tile_2016[\"tiles\"][0],\n",
    "\n",
    "    # Set the attribution and adjust the transparency of the layer\n",
    "    attr=\"GHG\", opacity = 0.5\n",
    ")\n",
    "\n",
    "# Add the layer to the map\n",
    "map_layer.add_to(aoi_map_bbox)\n",
    "\n",
    "# Visualize the map\n",
    "aoi_map_bbox"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we have successfully completed the following steps for the STAC collection for the U.S. Gridded Anthropogenic Methane Emissions Inventory dataset:\n",
    "\n",
    "1.  Install and import the necessary libraries\n",
    "2.  Fetch the collection from STAC collections using the appropriate endpoints\n",
    "3.  Count the number of existing granules within the collection\n",
    "4.  Map and compare the anthropogenic methane emissions for two distinctive months/years\n",
    "5.  Generate zonal statistics for the area of interest (AOI)\n",
    "6.  Generate a time-series graph of the anthropogenic methane emissions for a specified region\n",
    "\n",
    "If you have any questions regarding this user notebook, please contact us using the [feedback form](https://docs.google.com/forms/d/e/1FAIpQLSeVWCrnca08Gt_qoWYjTo6gnj1BEGL4NCUC9VEiQnXA02gzVQ/viewform)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
