{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: MiCASA Land Carbon Flux\n",
    "description: Global, daily 0.1 degree resolution carbon fluxes from net primary production (NPP), heterotrophic respiration (Rh), wildfire emissions (FIRE), fuel wood burning emissions (FUEL), net ecosystem exchange (NEE), and net biosphere exchange (NBE) derived from the MiCASA model, version 1\n",
    "authors: Siddharth Chaudhary, Vishal Gaur\n",
    "published: 10 April 2024\n",
    "execute:\n",
    "   freeze: true\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "1. Identify available dates and temporal frequency of observations for a given collection using the GHGC API `/stac` endpoint. The collection processed in this notebook is the Land-Atmosphere Carbon Flux data product\n",
    "2. Pass the STAC item into the raster API `/stac/tilejson.json` endpoint\n",
    "3. Using `folium.plugins.DualMap`, visualize two tiles (side-by-side), allowing time point comparison\n",
    "4. After the visualization, perform zonal statistics for a given polygon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data\n",
    "\n",
    "This dataset presents a variety of carbon flux parameters derived from the Más Informada Carnegie-Ames-Stanford-Approach (MiCASA) model. The model’s input data includes air temperature, precipitation, incident solar radiation, a soil classification map, and several satellite derived products. All model calculations are driven by analyzed meteorological data from NASA’s Modern-Era Retrospective analysis for Research and Application, Version 2 (MERRA-2). The resulting product provides global, daily data at 0.1 degree resolution from January 2001 through December 2023. It includes carbon flux variables expressed in units of kilograms of carbon per square meter per day (kg Carbon/m²/day) from net primary production (NPP), heterotrophic respiration (Rh), wildfire emissions (FIRE), fuel wood burning emissions (FUEL), net ecosystem exchange (NEE), and net biosphere exchange (NBE). The latter two are derived from the first four (see Scientific Details below). MiCASA is an extensive revision of the CASA – Global Fire Emissions Database, version 3 (CASA-GFED3) product. CASA-GFED3 and earlier versions of MERRA-driven CASA-GFED carbon fluxes have been used in several atmospheric carbon dioxide (CO₂) transport studies, serve as a community standard for priors of flux inversion systems, and through the support of NASA’s Carbon Monitoring System (CMS), help characterize, quantify, understand and predict the evolution of global carbon sources and sinks.\n",
    "\n",
    "For more information regarding this dataset, please visit the [U.S. Greenhouse Gas Center](https://earth.gov/ghgcenter)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install the Required Libraries\n",
    "Required libraries are pre-installed on the GHG Center Hub. If you need to run this notebook elsewhere, please install them with this line in a code cell:\n",
    "\n",
    "%pip install requests folium rasterstats pystac_client pandas matplotlib --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the STAC API\n",
    "First, we are going to import the required libraries. Once imported, they allow better executing a query in the GHG Center Spatio Temporal Asset Catalog (STAC) Application Programming Interface (API) where the granules for this collection are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the following libraries\n",
    "import requests\n",
    "import folium\n",
    "import folium.plugins\n",
    "from folium import Map, TileLayer\n",
    "from pystac_client import Client\n",
    "import branca\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the STAC and RASTER API endpoints\n",
    "# The endpoint is referring to a location within the API that executes a request on a data collection nesting on the server.\n",
    "\n",
    "# The STAC API is a catalog of all the existing data collections that are stored in the GHG Center.\n",
    "STAC_API_URL = \"https://earth.gov/ghgcenter/api/stac\"\n",
    "\n",
    "# The RASTER API is used to fetch collections for visualization\n",
    "RASTER_API_URL = \"https://earth.gov/ghgcenter/api/raster\"\n",
    "\n",
    "# The collection name is used to fetch the dataset from the STAC API. First, we define the collection name as a variable\n",
    "# Name of the collection for MiCASA Land Carbon Flux\n",
    "collection_name = \"micasa-carbonflux-daygrid-v1\"\n",
    "\n",
    "# Next, we need to specify the asset name for this collection\n",
    "# The asset name is referring to the raster band containing the pixel values for the parameter of interest\n",
    "# For the case of the MiCASA Land Carbon Flux collection, the parameter of interest is “rh”\n",
    "# rh = Heterotrophic Respiration\n",
    "asset_name = \"rh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the collection from the STAC API using the appropriate endpoint\n",
    "# The 'requests' library allows a HTTP request possible\n",
    "collection = requests.get(f\"{STAC_API_URL}/collections/{collection_name}\").json()\n",
    "\n",
    "# Print the properties of the collection to the console\n",
    "collection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the contents of our `collection` under the `temporal` variable, we see that the data is available from January 2003 to December 2023. By looking at the `dashboard:time density`, we observe that the periodic frequency of these observations is monthly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the required temporal information\n",
    "temporal_extent = collection['extent']['temporal']['interval'][0]\n",
    "start_date = temporal_extent[0].split('T')[0]\n",
    "end_date = temporal_extent[1].split('T')[0]\n",
    "temporal_resolution = collection['dashboard:time_density']\n",
    "\n",
    "# Final print statement\n",
    "print(f\"Start Date = {start_date}\")\n",
    "print(f\"End Date = {end_date}\")\n",
    "print(f\"Temporal Resolution = {temporal_resolution}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that would search for a data collection in the US GHG Center STAC API\n",
    "\n",
    "# First, we need to define the function\n",
    "# The name of the function = \"get_item_count\"\n",
    "# The argument that will be passed through the defined function = \"collection_id\"\n",
    "def get_item_count(collection_id):\n",
    "   \n",
    "    # Set a counter for the number of items existing in the collection\n",
    "    count = 0\n",
    "\n",
    "    # Define the path to retrieve the granules (items) of the collection of interest (MiCASA Land Carbon Flux) in the STAC API\n",
    "    items_url = f\"{STAC_API_URL}/collections/{collection_id}/items\"\n",
    "\n",
    "    # Run a while loop to make HTTP requests until there are no more URLs associated with the collection in the STAC API\n",
    "    while True:\n",
    "\n",
    "        # Retrieve information about the granules by sending a \"get\" request to the STAC API using the defined collection path\n",
    "        response = requests.get(items_url)\n",
    "\n",
    "        # If the items do not exist, print an error message and quit the loop\n",
    "        if not response.ok:\n",
    "            print(\"error getting items\")\n",
    "            exit()\n",
    "\n",
    "        # Return the results of the HTTP response as JSON\n",
    "        stac = response.json()\n",
    "       \n",
    "        # Increase the \"count\" by the number of items (granules) returned in the response\n",
    "        count += int(stac[\"context\"].get(\"returned\", 0))\n",
    "\n",
    "        # Retrieve information about the next URL associated with the collection (MiCASA Land Carbon Flux) in the STAC API (if applicable)\n",
    "        next = [link for link in stac[\"links\"] if link[\"rel\"] == \"next\"]\n",
    "\n",
    "        # Exit the loop if there are no other URLs\n",
    "        if not next:\n",
    "            break\n",
    "       \n",
    "        # Ensure the information gathered by other STAC API links associated with the collection are added to the original path\n",
    "        # \"href\" is the identifier for each of the tiles stored in the STAC API\n",
    "        items_url = next[0][\"href\"]\n",
    "        # temp = items_url.split('/')\n",
    "        # temp.insert(3, 'ghgcenter')\n",
    "        # temp.insert(4, 'api')\n",
    "        # temp.insert(5, 'stac')\n",
    "        # items_url = '/'.join(temp)\n",
    "\n",
    "    # Return the information about the total number of granules found associated with the collection (MiCASA Land Carbon Flux)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function created above \"get_item_count\" to the data collection\n",
    "number_of_items = get_item_count(collection_name)\n",
    "\n",
    "# Get the information about the number of granules found in the collection\n",
    "items = requests.get(f\"{STAC_API_URL}/collections/{collection_name}/items?limit=800\").json()[\"features\"]\n",
    "\n",
    "# Print the total number of items (granules) found\n",
    "print(f\"Found {len(items)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the first item in the collection\n",
    "# Keep in mind that a list starts from 0, 1, 2... therefore items[0] is referring to the first item in the list/collection\n",
    "items[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Changes in Carbon Flux Levels Using the Raster API\n",
    "We will explore changes in the land atmosphere Carbon flux `Heterotrophic Respiration` and examine their impacts over time. We'll then visualize the outputs on a map using `folium`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create a dictionary where the start datetime values for each granule is queried more explicitly by year and month (e.g., 2020-02)\n",
    "items = {item[\"properties\"][\"datetime\"][:10]: item for item in items}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we are entering the minimum and maximum values to provide our upper and lower bounds in the `rescale_values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the minimum and maximum values for rescaling\n",
    "rescale_values = {\"max\":items[list(items.keys())[0]][\"assets\"][asset_name][\"raster:bands\"][0][\"histogram\"][\"max\"], \"min\":items[list(items.keys())[0]][\"assets\"][asset_name][\"raster:bands\"][0][\"histogram\"][\"min\"]}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will pass the item id, collection name, asset name, and the `rescaling factor` to the `Raster API` endpoint. This step is done twice, once for December 2003 and again for December 2017, so that we can visualize each event independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a color for displaying the tiles\n",
    "# Please refer to matplotlib library if you'd prefer choosing a different color ramp.\n",
    "# For more information on Colormaps in Matplotlib, please visit https://matplotlib.org/stable/users/explain/colors/colormaps.html\n",
    "color_map = \"purd\"\n",
    "\n",
    "# Make a GET request to retrieve information for the date mentioned below\n",
    "date1 = '2023-01-01'\n",
    "date1_tile = requests.get(\n",
    "\n",
    "    # Pass the collection name, collection date, and its ID\n",
    "    # To change the year, month and date of the observed parameter, you can modify the date mentioned above.\n",
    "    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items[date1]['collection']}&item={items[date1]['id']}\"\n",
    "\n",
    "    # Pass the asset name\n",
    "    f\"&assets={asset_name}\"\n",
    "\n",
    "    # Pass the color formula and colormap for custom visualization\n",
    "    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n",
    "\n",
    "    # Pass the minimum and maximum values for rescaling\n",
    "    f\"&rescale={rescale_values['min']},{rescale_values['max']}\",\n",
    "\n",
    "# Return response in JSON format\n",
    ").json()\n",
    "\n",
    "# Print the properties of the retrieved granule to the console\n",
    "date1_tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a GET request to retrieve information for the date mentioned below\n",
    "date2 = '2023-01-31'\n",
    "date2_tile = requests.get(\n",
    "\n",
    "    # Pass the collection name, collection date, and its ID\n",
    "    # To change the year, month and date of the observed parameter, you can modify the date mentioned above.\n",
    "    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items[date2]['collection']}&item={items[date2]['id']}\"\n",
    "\n",
    "    # Pass the asset name\n",
    "    f\"&assets={asset_name}\"\n",
    "\n",
    "    # Pass the color formula and colormap for custom visualization\n",
    "    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n",
    "\n",
    "    # Pass the minimum and maximum values for rescaling\n",
    "    f\"&rescale={rescale_values['min']},{rescale_values['max']}\", \n",
    "\n",
    "# Return response in JSON format\n",
    ").json()\n",
    "\n",
    "# Print the properties of the retrieved granule to the console\n",
    "date2_tile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Land-Atmosphere Carbon Flux (Heterotrophic Respiration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this study we are going to compare the Rh level for date1 and date2 over the State of Texas \n",
    "# To change the location, you can simply insert the latitude and longitude of the area of your interest in the \"location=(LAT, LONG)\" statement\n",
    "# For example, you can change the current statement \"location=(31.9, -99.9)\" to \"location=(34, -118)\" to monitor the Rh level in California instead of Texas\n",
    "\n",
    "# Set initial zoom and center of map for CO₂ Layer\n",
    "# 'folium.plugins' allows mapping side-by-side\n",
    "map_ = folium.plugins.DualMap(location=(31.9, -99.9), zoom_start=6)\n",
    "\n",
    "\n",
    "# Define the first map layer with Rh level for the tile fetched for date 1\n",
    "# The TileLayer library helps in manipulating and displaying raster layers on a map\n",
    "map_layer_date1 = TileLayer(\n",
    "    tiles=date1_tile[\"tiles\"][0], # Path to retrieve the tile\n",
    "    attr=\"GHG\", # Set the attribution\n",
    "    opacity=0.8, # Adjust the transparency of the layer\n",
    "    name=f\"{date1} Rh Level\", # Title for the layer\n",
    "    overlay= True, # The layer can be overlaid on the map\n",
    "    legendEnabled = True # Enable displaying the legend on the map\n",
    ")\n",
    "\n",
    "# Add the first layer to the Dual Map\n",
    "map_layer_date1.add_to(map_.m1)\n",
    "\n",
    "\n",
    "# Define the first map layer with Rh level for the tile fetched for date 2\n",
    "map_layer_date2 = TileLayer(\n",
    "    tiles=date2_tile[\"tiles\"][0], # Path to retrieve the tile\n",
    "    attr=\"GHG\", # Set the attribution\n",
    "    opacity=0.8, # Adjust the transparency of the layer\n",
    "    name=f\"{date2} RH Level\", # Title for the layer\n",
    "    overlay= True, # The layer can be overlaid on the map\n",
    "    legendEnabled = True # Enable displaying the legend on the map\n",
    ")\n",
    "\n",
    "# Add the second layer to the Dual Map\n",
    "map_layer_date2.add_to(map_.m2)\n",
    "\n",
    "# Display data markers (titles) on both maps\n",
    "folium.Marker((40, 5.0), tooltip=\"both\").add_to(map_)\n",
    "\n",
    "# Add a layer control to switch between map layers\n",
    "folium.LayerControl(collapsed=False).add_to(map_)\n",
    "\n",
    "# Add a legend to the dual map using the 'branca' library. \n",
    "# Note: the inserted legend is representing the minimum and maximum values for both tiles.\n",
    "colormap = branca.colormap.linear.PuRd_09.scale(0, 0.3) # minimum value = 0, maximum value = 0.3 (kg Carbon/m2/daily)\n",
    "\n",
    "# Classify the colormap according to specified Rh values \n",
    "colormap = colormap.to_step(index=[0, 0.07, 0.15, 0.22, 0.3])\n",
    "\n",
    "# Add the data unit as caption\n",
    "colormap.caption = 'Rh Values (gm Carbon/m2/daily)'\n",
    "\n",
    "# Display the legend and caption on the map\n",
    "colormap.add_to(map_.m1)\n",
    "\n",
    "# Visualize the Dual Map\n",
    "map_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Zonal Statistics\n",
    "To perform zonal statistics, first we need to create a polygon. In this use case we are creating a polygon in Texas, United States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Area of Interest (AOI) is set to Dallas, Texas (USA)\n",
    "texas_dallas_aoi = {\n",
    "    \"type\": \"Feature\", # Create a feature object\n",
    "    \"properties\": {},\n",
    "    \"geometry\": { # Set the bounding coordinates for the polygon\n",
    "        \"coordinates\": [\n",
    "            [\n",
    "                # [longitude, latitude]\n",
    "                [-96.1, 32.28],  # Southeast Bounding Coordinate\n",
    "                [-96.1, 33.28],  # Northeast Bounding Coordinate\n",
    "                [-97.58, 33.28], # Northwest Bounding Coordinate\n",
    "                [-97.58, 32.28],  # Southwest Bounding Coordinate\n",
    "                [-96.1, 32.28]   # Closing the polygon at the Southeast Bounding Coordinate\n",
    "            ]\n",
    "        ],\n",
    "        \"type\": \"Polygon\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new map to display the generated polygon\n",
    "aoi_map = Map(\n",
    "\n",
    "    # Base map is set to OpenStreetMap\n",
    "    tiles=\"OpenStreetMap\",\n",
    "\n",
    "    # Define the spatial properties for the map\n",
    "    location=[\n",
    "        32.81,-96.93, # coordinates for Dallas, Texas area\n",
    "    ],\n",
    "\n",
    "    # Set the zoom value\n",
    "    zoom_start=9, # zoom in or out by increasing or decreasing the value here\n",
    ")\n",
    "\n",
    "# Insert the Dallas, TX polygon to the map\n",
    "folium.GeoJson(texas_dallas_aoi, name=\"Texas, Dallas\").add_to(aoi_map)\n",
    "\n",
    "# Visualize the map\n",
    "aoi_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we generate stats for a specific item (observation), we first check the total number of items available within the collection and retrieve the information regarding their start datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the total number of items available within the collection\n",
    "items = requests.get(\n",
    "    f\"{STAC_API_URL}/collections/{collection_name}/items?limit=800\"\n",
    ").json()[\"features\"]\n",
    "\n",
    "# Print the total number of items (granules) found\n",
    "print(f\"Found {len(items)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the first item in the collection\n",
    "items[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to develop a function that runs through the data collection and generates the statistics for a specific item (granule) within the boundaries of the AOI polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bounding box should be passed to the geojson param as a geojson Feature or FeatureCollection\n",
    "# Create a function that retrieves information regarding a specific granule using its asset name and raster identifier and generates the statistics for it\n",
    "\n",
    "# The function takes an item (granule) and a JSON (Dallas, TX polygon) as input parameters\n",
    "def generate_stats(item, geojson):\n",
    "\n",
    "    # A POST request is made to submit the data associated with the item of interest (specific observation) within the Dallas, TX boundaries to compute its statistics\n",
    "    result = requests.post(\n",
    "\n",
    "        # Raster API Endpoint for computing statistics\n",
    "        f\"{RASTER_API_URL}/cog/statistics\",\n",
    "\n",
    "        # Pass the URL to the item, asset name, and raster identifier as parameters\n",
    "        params={\"url\": item[\"assets\"][asset_name][\"href\"]},\n",
    "\n",
    "        # Send the GeoJSON object (Dallas, TX polygon) along with the request\n",
    "        json=geojson,\n",
    "\n",
    "    # Return the response in JSON format\n",
    "    ).json()\n",
    "\n",
    "    # Print the result\n",
    "    print(result)\n",
    "\n",
    "    # Return a dictionary containing the computed statistics along with the item's datetime information\n",
    "    return {\n",
    "        **result[\"properties\"],\n",
    "        \"datetime\": item[\"properties\"][\"datetime\"][:10],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a for loop that iterates over all the existing items in the collection\n",
    "for item in items:\n",
    "\n",
    "    # The loop will then retrieve the information for the start datetime of each item in the list\n",
    "    print(item[\"properties\"][\"datetime\"])\n",
    "\n",
    "    # Exit the loop after printing the start datetime for the first item in the collection\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the statistics for the AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# %%time = Wall time (execution time) for running the code below\n",
    "\n",
    "# Generate statistics using the created function \"generate_stats\" within the bounding box defined by the \"texas_dallas_aoi\" polygon\n",
    "stats = [generate_stats(item, texas_dallas_aoi) for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the stats for the first item in the collection\n",
    "stats[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that goes through every single item in the collection and populates their properties - including the minimum, maximum, and sum of their values - in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that converts statistics in JSON format into a pandas DataFrame\n",
    "def clean_stats(stats_json) -> pd.DataFrame:\n",
    "\n",
    "    # Normalize the JSON data\n",
    "    df = pd.json_normalize(stats_json)\n",
    "\n",
    "    # Replace the naming \"statistics.b1\" in the columns\n",
    "    df.columns = [col.replace(\"statistics.b1.\", \"\") for col in df.columns]\n",
    "\n",
    "    # Set the datetime format\n",
    "    df[\"date\"] = pd.to_datetime(df[\"datetime\"])\n",
    "\n",
    "    # Return the cleaned format\n",
    "    return df\n",
    "\n",
    "# Apply the generated function on the stats data\n",
    "df = clean_stats(stats)\n",
    "\n",
    "# Display the stats for the first 5 granules in the collection in the table\n",
    "# Change the value in the parenthesis to show more or a smaller number of rows in the table\n",
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data as a Time Series\n",
    "We can now explore the Heterotrophic Respiration time series (October 2021 - January 2024) available for the Dallas, Texas area. We can plot the data set using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the width and height of the plot using the 'matplotlib' library\n",
    "# Figure size: 20 representing the width, 10 representing the height\n",
    "fig = plt.figure(figsize=(20, 10)) \n",
    "\n",
    "# Plot the time series analysis of the daily Heterotrophic Respiration changes in Dallas, Texas\n",
    "plt.plot(\n",
    "    df[\"date\"], # X-axis: date\n",
    "    df[\"max\"], # Y-axis: Rh value\n",
    "    color=\"purple\", # Line color\n",
    "    linestyle=\"-\", # Line style\n",
    "    linewidth=0.5, # Line width\n",
    "    label=\"RH Level\", # Legend label\n",
    ")\n",
    "\n",
    "# Display legend\n",
    "plt.legend()\n",
    "\n",
    "# Insert label for the X-axis\n",
    "plt.xlabel(\"Years\")\n",
    "\n",
    "# Insert label for the Y-axis\n",
    "plt.ylabel(\"gm Carbon/m2/day\")\n",
    "\n",
    "# Insert title for the plot\n",
    "plt.title(\"Heterotrophic Respiration Values for Dallas, Texas (October 2021 to January 2024)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take a closer look at the daily Heterotrophic Respiration variability across this region, we are going to retrieve and display data collected during the December, 2023 observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the third item in the list as the observation item.\n",
    "# Considering that a list starts with \"0\", we need to insert \"2\" in the \"items[2]\" statement\n",
    "# Print the start Date Time of the third granule in the collection\n",
    "print(items[2][\"properties\"][\"datetime\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A GET request is made for the observed tile\n",
    "observed_tile = requests.get(\n",
    "\n",
    "    # Pass the collection name, the item number in the list, and its ID\n",
    "    f\"{RASTER_API_URL}/stac/tilejson.json?collection={items[2]['collection']}&item={items[2]['id']}\"\n",
    "\n",
    "    # Pass the asset name\n",
    "    f\"&assets={asset_name}\"\n",
    "\n",
    "    # Pass the color formula and colormap for custom visualization\n",
    "    f\"&color_formula=gamma+r+1.05&colormap_name={color_map}\"\n",
    "\n",
    "    # Pass the minimum and maximum values for rescaling\n",
    "    f\"&rescale={rescale_values['min']},{rescale_values['max']}\",\n",
    "\n",
    "# Return the response in JSON format\n",
    ").json()\n",
    "\n",
    "# Print the properties of the retrieved granule to the console \n",
    "observed_tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new map to display the Rh level for the Dallas, Texas area for the observed tile timeframe.\n",
    "aoi_map_bbox = Map(\n",
    "\n",
    "    # Base map is set to OpenStreetMap\n",
    "    tiles=\"OpenStreetMap\",\n",
    "\n",
    "    # Set the center of the map\n",
    "    location=[\n",
    "        32.8, # latitude\n",
    "        -96.79, # longitude\n",
    "    ],\n",
    "\n",
    "    # Set the zoom value\n",
    "    zoom_start=9,\n",
    ")\n",
    "\n",
    "# Define the map layer with the Rh level for observed tile\n",
    "map_layer = TileLayer(\n",
    "    tiles=observed_tile[\"tiles\"][0], # Path to retrieve the tile\n",
    "\n",
    "    # Set the attribution, transparency, and the title along with enabling the visualization of the legend on the map \n",
    "    attr=\"GHG\", opacity = 0.7, name=\" Observed tile RH Level\", overlay= True, legendEnabled = True\n",
    ")\n",
    "\n",
    "# Add the layer to the map\n",
    "map_layer.add_to(aoi_map_bbox)\n",
    "\n",
    "# Display data marker (title) on the map\n",
    "folium.Marker((40, 5.9), tooltip=\"both\").add_to(aoi_map_bbox)\n",
    "\n",
    "# Add a layer control\n",
    "folium.LayerControl(collapsed=False).add_to(aoi_map_bbox)\n",
    "\n",
    "# Add a legend using the 'branca' library\n",
    "colormap = branca.colormap.linear.PuRd_09.scale(0, 0.3) # minimum value = 0, maximum value = 0.3 (gm Carbon/m2/daily)\n",
    "\n",
    "# Classify the colormap according to the specified Rh values\n",
    "colormap = colormap.to_step(index=[0, 0.07, 0.15, 0.22, 0.3])\n",
    "\n",
    "# Add the data unit as caption\n",
    "colormap.caption = 'Rh Values (gm Carbon/m2/daily)'\n",
    "\n",
    "# Display the legend and caption on the map\n",
    "colormap.add_to(aoi_map_bbox)\n",
    "\n",
    "# Visualize the map\n",
    "aoi_map_bbox"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we have successfully completed the following steps for the STAC collection for MiCASA Land Carbon Flux data:\n",
    "1.\tInstall and import the necessary libraries \n",
    "2.\tFetch the collection from STAC collections using the appropriate endpoints\n",
    "3.\tCount the number of existing granules within the collection\n",
    "4.\tMap and compare the Heterotrophic Respiration (Rh) levels over the Dallas, Texas area for two distinctive years\n",
    "5.\tCreate a table that displays the minimum, maximum, and sum of the Rh values for a specified region\n",
    "6.\tGenerate a time-series graph of the Rh values for a specified region\n",
    "\n",
    "If you have any questions regarding this user notebook, please contact us using the [feedback form](https://docs.google.com/forms/d/e/1FAIpQLSeVWCrnca08Gt_qoWYjTo6gnj1BEGL4NCUC9VEiQnXA02gzVQ/viewform). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
