{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9278721-c17c-48e5-996d-f045c75a83f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from glob import glob\n",
    "import pathlib\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import calendar\n",
    "import seaborn as sns\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c6638-5e7c-4b1f-8c52-84ffdec908ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the year you want to run validation on\n",
    "vyear=2022 # summary json files will be later generated for the year you provide here\n",
    "data_dir=\"data/\" # make sure you have the data for vyear in your data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4821a749-3f15-47c8-b3c3-ef6ebdba0563",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "s3_client = session.client(\"s3\")\n",
    "\n",
    "dataset_name= \"odiac-ffco2-monthgrid-v2023\"\n",
    "cog_data_bucket=\"ghgc-data-store-develop\"\n",
    "cog_data_prefix = f\"transformed_cogs/{dataset_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d125a5a-0617-4ded-a79a-17063f1d87d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_s3_keys(bucket, model_name, ext):\n",
    "    \"\"\"Get a list of all keys in an S3 bucket.\"\"\"\n",
    "    keys = []\n",
    "\n",
    "    kwargs = {\"Bucket\": bucket, \"Prefix\": f\"{model_name}/\"}\n",
    "    while True:\n",
    "        resp = s3_client.list_objects_v2(**kwargs)\n",
    "        for obj in resp[\"Contents\"]:\n",
    "            if obj[\"Key\"].endswith(ext) and \"historical\" not in obj[\"Key\"]:\n",
    "                keys.append(obj[\"Key\"])\n",
    "\n",
    "        try:\n",
    "            kwargs[\"ContinuationToken\"] = resp[\"NextContinuationToken\"]\n",
    "        except KeyError:\n",
    "            break\n",
    "\n",
    "    return keys\n",
    "\n",
    "keys = get_all_s3_keys(cog_data_bucket, cog_data_prefix, \".tif\")\n",
    "\n",
    "# Extract only the COGs for selected year\n",
    "pattern = re.compile(rf'{vyear}(0[1-9]|1[0-2])')\n",
    "keys = [path for path in keys if pattern.search(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0547c33e-53ea-414b-a4e7-2d9017112829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the summary variables\n",
    "summary_dict_netcdf, summary_dict_cog = {}, {}\n",
    "overall_stats_netcdf, overall_stats_cog = {}, {}\n",
    "full_data_df_netcdf, full_data_df_cog = pd.DataFrame(), pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab020ef-8244-4ae5-b97c-e2f724a8c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the COGs to get the statistics\n",
    "for key in keys:\n",
    "    url=f\"s3://{cog_data_bucket}/{key}\"\n",
    "    with rasterio.open(url) as src:\n",
    "        filename_elements = re.split(\"[_ ? . ]\", url)\n",
    "        for band in src.indexes:\n",
    "            print(\"_\".join(filename_elements[1:6]))\n",
    "            idx = pd.MultiIndex.from_product(\n",
    "                    [\n",
    "                        [\"_\".join(filename_elements[1:6])],\n",
    "                        [filename_elements[5]],\n",
    "                        [x for x in np.arange(1, src.height + 1)],\n",
    "                    ]\n",
    "                )\n",
    "            raster_data = src.read(band)\n",
    "            raster_data[raster_data == -9999] = 0 # because we did that in the transformation script\n",
    "            temp = pd.DataFrame(index=idx, data=raster_data)\n",
    "            full_data_df_cog = full_data_df_cog._append(temp, ignore_index=False)\n",
    "\n",
    "            # Calculate summary statistics\n",
    "            min_value = np.float64(temp.values.min())\n",
    "            max_value = np.float64(temp.values.max())\n",
    "            mean_value = np.float64(temp.values.mean())\n",
    "            std_value = np.float64(temp.values.std())\n",
    "\n",
    "            summary_dict_cog[\n",
    "                    f'{\"_\".join(filename_elements[1:5])}_{filename_elements[5][:4]}_{calendar.month_name[int(filename_elements[5][4:])]}'\n",
    "                ] = {\n",
    "                    \"min_value\": min_value,\n",
    "                    \"max_value\": max_value,\n",
    "                    \"mean_value\": mean_value,\n",
    "                    \"std_value\": std_value,\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee5f4a-9b22-4853-9fa9-bb69555d392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the raw files for selected year to get the statistics \n",
    "tif_files = glob(f\"{data_dir}{vyear}/*.tif\", recursive=True)\n",
    "for tif_file in tif_files:\n",
    "    file_name = pathlib.Path(tif_file).name[:-4]\n",
    "    print(file_name)\n",
    "    with rasterio.open(tif_file) as src:\n",
    "        for band in src.indexes:\n",
    "            idx = pd.MultiIndex.from_product(\n",
    "                [\n",
    "                    [pathlib.Path(tif_file).name[:-9]],\n",
    "                    [pathlib.Path(tif_file).name[-8:-4]],\n",
    "                    [x for x in np.arange(1, src.height + 1)],\n",
    "                ]\n",
    "            )\n",
    "            # Read the raster data\n",
    "            raster_data = src.read(band)\n",
    "            #raster_data[raster_data == -9999] = np.nan\n",
    "            temp = pd.DataFrame(index=idx, data=raster_data)\n",
    "            full_data_df_netcdf = full_data_df_netcdf._append(temp, ignore_index=False)\n",
    "\n",
    "            # Calculate summary statistics\n",
    "            min_value = np.float64(temp.values.min())\n",
    "            max_value = np.float64(temp.values.max())\n",
    "            mean_value = np.float64(temp.values.mean())\n",
    "            std_value = np.float64(temp.values.std())\n",
    "\n",
    "            summary_dict_netcdf[\n",
    "                f'{tif_file.split(\"/\")[-1][:-9]}_{calendar.month_name[int(tif_file.split(\"/\")[-1][-6:-4])]}'\n",
    "            ] = {\n",
    "                \"min_value\": min_value,\n",
    "                \"max_value\": max_value,\n",
    "                \"mean_value\": mean_value,\n",
    "                \"std_value\": std_value,\n",
    "            }\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c84f40-09ba-43dd-882e-8dd677ffeb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge monthly stats for COGs and raw files in a csv file \n",
    "cog_df = pd.DataFrame(summary_dict_cog).T.reset_index()\n",
    "raw_df = pd.DataFrame(summary_dict_netcdf).T.reset_index()\n",
    "cog_df['date']= cog_df[\"index\"].apply(lambda x: (x.split(\"_\")[-1]+x.split(\"_\")[-2]) )\n",
    "raw_df['date']= raw_df[\"index\"].apply(lambda x: (x.split(\"_\")[-1]+str(vyear)) )\n",
    "check_df=pd.merge(cog_df, raw_df[[\"min_value\",\"max_value\",\"mean_value\",\"std_value\",\"date\"]], how='inner', on='date',suffixes=('', '_raw'))\n",
    "check_df.to_csv(f\"monthly_stats_{vyear}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22d99fa-9928-4a4d-9b51-b1ef81243144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the overall data stat for that year\n",
    "overall_stats_netcdf[\"min_value\"] = np.float64(full_data_df_netcdf.values.min())\n",
    "overall_stats_netcdf[\"max_value\"] = np.float64(full_data_df_netcdf.values.max())\n",
    "overall_stats_netcdf[\"mean_value\"] = np.float64(full_data_df_netcdf.values.mean())\n",
    "overall_stats_netcdf[\"std_value\"] = np.float64(full_data_df_netcdf.values.std())\n",
    "\n",
    "overall_stats_cog[\"min_value\"] = np.float64(full_data_df_cog.values.min())\n",
    "overall_stats_cog[\"max_value\"] = np.float64(full_data_df_cog.values.max())\n",
    "overall_stats_cog[\"mean_value\"] = np.float64(full_data_df_cog.values.mean())\n",
    "overall_stats_cog[\"std_value\"] = np.float64(full_data_df_cog.values.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7043a89-0c69-4783-a9d6-334dbdc1a923",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {\n",
    "    \"Stats for raw netCDF files.\": summary_dict_netcdf,\n",
    "    \"Stats for transformed COG files.\": summary_dict_cog\n",
    "}\n",
    "\n",
    "# Writing to JSON file\n",
    "with open(f\"monthly_stats_{vyear}.json\", \"w\") as fp:\n",
    "    json.dump(data, fp, indent=4) \n",
    "\n",
    "data = {\n",
    "    \"Stats for raw netCDF files.\": overall_stats_netcdf,\n",
    "    \"Stats for transformed COG files.\": overall_stats_cog\n",
    "}\n",
    "\n",
    "# Writing to JSON file\n",
    "with open(f\"overall_stats_{vyear}.json\", \"w\") as fp:\n",
    "    json.dump(data, fp, indent=4) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
